"""
This module contains utility functions used in the conversion of the downloaded
data to TFrecords as well as functions used by the model/training script.

Semantic segmenation evaluations methods were taken from
https://github.com/martinkersner/py_img_seg_eval
"""

import os
import fnmatch
import logging

import cv2
import numpy as np
from PIL import Image
from tqdm import tqdm
import tensorflow as tf


def set_logging_verbosity(verbose_level=3):
    """Set the level of logging verbosity."""

    if not isinstance(verbose_level, int):
        raise TypeError("verbose_level must be an int")

    if not (0 <= verbose_level <= 4):
        raise ValueError("verbose_level must be between 0 and 4")

    verbosity = [logging.CRITICAL,
                 logging.ERROR,
                 logging.WARNING,
                 logging.INFO,
                 logging.DEBUG]

    logging.basicConfig(
        format='%(asctime)s:\t %(message)s',
        datefmt='%m/%d/%Y %I:%M:%S %p',
        level=verbosity[verbose_level])

def compute_batch_iou(predicted_masks, ground_truth_masks):
    """
    Compute the the average IoU across a batch of ground truth masks and their
    respective predicted masks given by the network.
    """

    return np.mean(
        [mean_IU(np.squeeze(predicted_masks[i]), np.squeeze(ground_truth_masks[i]))
         for i in range(len(predicted_masks))])

def compute_batch_pixel_accuracy(predicted_masks, ground_truth_masks):
    """
    Compute the the average pixel accuracy across a batch of ground truth masks
    and their respective predicted masks given by the network.
    """

    return np.mean(
        [pixel_accuracy(np.squeeze(predicted_masks[i]), np.squeeze(ground_truth_masks[i]))
         for i in range(len(predicted_masks))])

def load_data_paths(data_root_directory, extra_ignore_regexes=None):
    """
    Provide a generic function to load paths of image data files.

    This function loads only the `string` paths, it does not load images into memory.
    """

    root_path = os.path.realpath(data_root_directory)

    # Load the image file extensions that the scanner uses
    extensions = ['.png', '.jpg']

    full_file_list = []
    for ext in extensions:
        # Using os.walk and fnmatch here instead of glob to remain compatible
        # with Python 2
        file_list = [os.path.join(dir_path, f)
                     for dir_path, dirnames, files in os.walk(root_path)
                     for f in fnmatch.filter(files, '*' + ext)]

        full_file_list.extend(file_list)

    for scan_path in full_file_list:
        yield scan_path

def _bytes_feature(value):
    """Convert a bytearray into a Feature."""
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))

def _int64_feature(value):
    """Convert a scalar int into a Feature."""
    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))

def build_semseg_record(images_to_masks, tfrecords_filename, resize_dims):
    """Convert an iterable of paths to semseg images into a TFRecords object."""
    writer = tf.python_io.TFRecordWriter(tfrecords_filename)

    for image_path, mask_path in tqdm(images_to_masks.items()):

        image = cv2.imread(image_path)
        mask = cv2.imread(mask_path, 0)

        mask = cv2.resize(mask, resize_dims[::-1], interpolation=cv2.INTER_AREA)
        image = cv2.resize(image, resize_dims[::-1], interpolation=cv2.INTER_AREA)

        # Save original dimensions
        h, w, _ = image.shape

        # Add axis for QueueRunners
        mask = np.expand_dims(mask, axis=-1)

        # convert the image and mask to their raw bytes repr
        mask_raw = mask.tostring()
        image_raw = image.tostring()

        # Encode one example at a time
        example = tf.train.Example(features=tf.train.Features(feature={
            'original_height': _int64_feature(h),
            'original_width': _int64_feature(w),
            'resized_height': _int64_feature(resize_dims[0]),
            'resized_width': _int64_feature(resize_dims[1]),
            'image_raw': _bytes_feature(image_raw),
            'mask_raw': _bytes_feature(mask_raw)}))

        writer.write(example.SerializeToString())

    writer.close()

def symbolic_read_and_decode_semseg_tfrecord(
    filename_queue, resize_dims, batch_size, num_threads, min_after_dequeue):
    """
    Given a TFRecord file generated by `kml.utils.serialize.semseg_files_to_tfrecords`,
    construct symbolic (image, mask) batches from it, adding all
    relevant ops to the graph.
    """

    reader = tf.TFRecordReader()

    _, serialized_example = reader.read(filename_queue)

    features = tf.parse_single_example(
      serialized_example,
      features={
        'original_height': tf.FixedLenFeature([], tf.int64),
        'original_width': tf.FixedLenFeature([], tf.int64),
        'resized_height': tf.FixedLenFeature([], tf.int64),
        'resized_width': tf.FixedLenFeature([], tf.int64),
        'image_raw': tf.FixedLenFeature([], tf.string),
        'mask_raw': tf.FixedLenFeature([], tf.string)})

    # Decode the image/mask back from bytes to uint8
    image = tf.decode_raw(features['image_raw'], tf.uint8)
    mask = tf.decode_raw(features['mask_raw'], tf.uint8)

    # Reshape to the image's original shape
    image = tf.reshape(image, (*resize_dims, 3))
    mask = tf.reshape(mask, (*resize_dims, 1))

    # Use capacity formula recommended by tensorflow
    capacity = min_after_dequeue + (num_threads + 1) * batch_size

    # Add queue/shuffling related ops to the graph
    image_batch, mask_batch= tf.train.shuffle_batch(
        [image, mask], batch_size=batch_size, capacity=capacity,
        num_threads=num_threads, min_after_dequeue=min_after_dequeue)

    return image_batch, mask_batch

def build_tfrecords_batch(*paths_to_tfrecords, image_shape, batch_size, max_iterations, min_after_dequeue=100):
    """Build tensors for a batch of data given the path to tfrecord file"""
    filename_queue = tf.train.string_input_producer(
            [*paths_to_tfrecords], num_epochs=max_iterations)

    image_batch, label_batch = symbolic_read_and_decode_semseg_tfrecord(
            filename_queue, image_shape, batch_size=batch_size,
            num_threads=4, min_after_dequeue=min_after_dequeue)

    return image_batch, label_batch

def pixel_accuracy(eval_segm, gt_segm):
    """Compute pixel-wise accuray: sum_i(n_ii) / sum_i(t_i)"""
    check_size(eval_segm, gt_segm)

    cl, n_cl = extract_classes(gt_segm)
    eval_mask, gt_mask = extract_both_masks(eval_segm, gt_segm, cl, n_cl)

    sum_n_ii = 0
    sum_t_i  = 0

    for i, c in enumerate(cl):
        curr_eval_mask = eval_mask[i, :, :]
        curr_gt_mask = gt_mask[i, :, :]

        sum_n_ii += np.sum(np.logical_and(curr_eval_mask, curr_gt_mask))
        sum_t_i  += np.sum(curr_gt_mask)

    if (sum_t_i == 0):
        pixel_accuracy_ = 0
    else:
        pixel_accuracy_ = sum_n_ii / sum_t_i

    return pixel_accuracy_

def mean_IU(eval_segm, gt_segm):
    """
    Compute average IoU of an image:
    (1/n_cl) * sum_i(n_ii / (t_i + sum_j(n_ji) - n_ii))
    """

    check_size(eval_segm, gt_segm)

    cl, n_cl   = union_classes(eval_segm, gt_segm)
    _, n_cl_gt = extract_classes(gt_segm)
    eval_mask, gt_mask = extract_both_masks(eval_segm, gt_segm, cl, n_cl)

    IU = list([0]) * n_cl

    for i, c in enumerate(cl):
        curr_eval_mask = eval_mask[i, :, :]
        curr_gt_mask = gt_mask[i, :, :]

        if (np.sum(curr_eval_mask) == 0) or (np.sum(curr_gt_mask) == 0):
            continue

        n_ii = np.sum(np.logical_and(curr_eval_mask, curr_gt_mask))
        t_i  = np.sum(curr_gt_mask)
        n_ij = np.sum(curr_eval_mask)

        IU[i] = n_ii / (t_i + n_ij - n_ii)

    mean_IU_ = np.sum(IU) / n_cl_gt
    return mean_IU_

def extract_both_masks(eval_segm, gt_segm, cl, n_cl):
    """Remap both masks to ascending consecutive integers."""
    eval_mask = extract_masks(eval_segm, cl, n_cl)
    gt_mask   = extract_masks(gt_segm, cl, n_cl)

    return eval_mask, gt_mask

def extract_classes(segm):
    """Extract class info from mask."""
    cl = np.unique(segm)
    n_cl = len(cl)

    return cl, n_cl

def union_classes(eval_segm, gt_segm):
    """Find the union of the two masks."""
    eval_cl, _ = extract_classes(eval_segm)
    gt_cl, _   = extract_classes(gt_segm)

    cl = np.union1d(eval_cl, gt_cl)
    n_cl = len(cl)

    return cl, n_cl

def extract_masks(segm, cl, n_cl):
    """Remap masks to ascending consecutive integers."""
    h, w  = segm_size(segm)
    masks = np.zeros((n_cl, h, w))

    for i, c in enumerate(cl):
        masks[i, :, :] = segm == c

    return masks

def segm_size(segm):
        """Color agnostic helper method to check shape."""
        try:
            height = segm.shape[0]
            width  = segm.shape[1]
        except IndexError:
            raise

        return height, width

def check_size(eval_segm, gt_segm):
    """Ensure images have same shape."""
    h_e, w_e = segm_size(eval_segm)
    h_g, w_g = segm_size(gt_segm)

    if (h_e != h_g) or (w_e != w_g):
        raise ValueError("DiffDim: Different dimensions of matrices!")

def add_color(img, num_classes=32):
    """Given a 1-channel color map; convert it to a colored mask."""
    h, w = img.shape
    img_color = np.zeros((h, w, 3))
    for i in range(1, 151):
        img_color[img == i] = to_color(i)
    img_color[img == num_classes] = (1.0, 1.0, 1.0)
    return img_color

def to_color(category):
    """Map each category color a good distance away from each other on the HSV color space."""
    import colorsys
    v = (category - 1) * (137.5 / 360)
    return colorsys.hsv_to_rgb(v, 1, 1)
